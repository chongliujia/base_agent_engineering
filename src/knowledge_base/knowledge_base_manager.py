"""
çŸ¥è¯†åº“ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ–‡æ¡£å¤„ç†å’Œå‘é‡å­˜å‚¨
"""

import asyncio
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from datetime import datetime

from langchain_core.documents import Document

from .document_processor import DocumentProcessor, DocumentValidator
from .vector_store_manager import VectorStoreManager
from config.settings import get_settings


class KnowledgeBaseManager:
    """çŸ¥è¯†åº“ç®¡ç†å™¨ - æ”¯æŒå¤šçŸ¥è¯†åº“å’Œå¤šç§åˆ†å—ç­–ç•¥"""
    
    def __init__(self, collection_name: str = None, chunking_strategy: str = "recursive", strategy_params: Dict[str, Any] = None):
        self.settings = get_settings()
        self.doc_processor = DocumentProcessor(
            chunking_strategy=chunking_strategy, 
            strategy_params=strategy_params or {}
        )
        
        # è®¾ç½®å½“å‰çŸ¥è¯†åº“åç§°
        self.current_collection = collection_name or self.settings.current_collection_name
        self.vector_manager = VectorStoreManager(collection_name=self.current_collection)
        
        # åˆ›å»ºçŸ¥è¯†åº“æ ¹ç›®å½•
        self.knowledge_base_root = Path(self.settings.knowledge_base_path)
        self.knowledge_base_root.mkdir(exist_ok=True)
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†åº“åˆ›å»ºç‹¬ç«‹çš„ç›®å½•
        self.knowledge_base_path = self.knowledge_base_root / self.current_collection
        self.knowledge_base_path.mkdir(exist_ok=True)
        
        # åˆ›å»ºå…ƒæ•°æ®å­˜å‚¨ç›®å½•
        self.metadata_path = self.knowledge_base_path / "metadata"
        self.metadata_path.mkdir(exist_ok=True)
    
    def save_processing_metadata(self, metadata: Dict[str, Any], 
                               filename: str = "processing_log.json"):
        """ä¿å­˜å¤„ç†å…ƒæ•°æ®"""
        metadata_file = self.metadata_path / filename
        
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼ŒåŠ è½½ç°æœ‰æ•°æ®
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        else:
            existing_data = {"processing_history": []}
        
        # æ·»åŠ æ–°çš„å¤„ç†è®°å½•
        existing_data["processing_history"].append(metadata)
        existing_data["last_updated"] = datetime.now().isoformat()
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
    
    def load_processing_metadata(self, filename: str = "processing_log.json") -> Dict[str, Any]:
        """åŠ è½½å¤„ç†å…ƒæ•°æ®"""
        metadata_file = self.metadata_path / filename
        
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {"processing_history": []}
    
    async def add_file(self, file_path: Union[str, Path], chunking_strategy: str = None, strategy_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ·»åŠ å•ä¸ªæ–‡ä»¶åˆ°çŸ¥è¯†åº“ï¼ˆæ”¯æŒä¸´æ—¶æŒ‡å®šåˆ†å—ç­–ç•¥ï¼‰"""
        try:
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path}")
            
            # 1. å¤„ç†æ–‡æ¡£ï¼ˆæ”¯æŒä¸´æ—¶ç­–ç•¥ï¼‰
            documents = self.doc_processor.process_file(
                file_path, 
                chunking_strategy=chunking_strategy, 
                strategy_params=strategy_params
            )
            
            # 2. éªŒè¯æ–‡æ¡£
            valid_documents = DocumentValidator.validate_documents(documents)
            
            if not valid_documents:
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹",
                    "file_path": str(file_path)
                }
            
            # 3. å‘é‡åŒ–å¹¶å­˜å‚¨
            result = await self.vector_manager.add_documents(valid_documents)
            
            # 4. ä¿å­˜å…ƒæ•°æ®ï¼ˆåŒ…å«ç­–ç•¥ä¿¡æ¯ï¼‰
            strategy_info = self.doc_processor.get_strategy_info()
            metadata = {
                "operation": "add_file",
                "file_path": str(file_path),
                "timestamp": datetime.now().isoformat(),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents),
                "chunking_strategy": strategy_info.get("name", "unknown"),
                "strategy_params": strategy_info.get("parameters", {}),
                "vector_result": result
            }
            
            self.save_processing_metadata(metadata)
            
            result.update({
                "file_path": str(file_path),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents)
            })
            
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "message": f"å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}",
                "file_path": str(file_path)
            }
            
            # ä¿å­˜é”™è¯¯å…ƒæ•°æ®
            strategy_info = self.doc_processor.get_strategy_info()
            error_metadata = {
                "operation": "add_file",
                "file_path": str(file_path),
                "timestamp": datetime.now().isoformat(),
                "chunking_strategy": strategy_info.get("name", "unknown"),
                "error": str(e),
                "success": False
            }
            
            self.save_processing_metadata(error_metadata)
            
            return error_result
    
    async def add_directory(self, directory_path: Union[str, Path], 
                          recursive: bool = True,
                          auto_strategy: bool = True,
                          chunking_strategy: str = None,
                          strategy_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ·»åŠ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ°çŸ¥è¯†åº“ï¼ˆæ”¯æŒè‡ªåŠ¨ç­–ç•¥é€‰æ‹©å’Œæ ¼å¼ç‰¹å®šå¤„ç†ï¼‰"""
        try:
            print(f"ğŸ“ å¤„ç†ç›®å½•: {directory_path}")
            
            # 1. å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£ï¼ˆæ”¯æŒå¤šç§ç­–ç•¥ï¼‰
            documents = self.doc_processor.process_directory(
                directory_path, 
                recursive=recursive,
                auto_strategy=auto_strategy,
                chunking_strategy=chunking_strategy,
                strategy_params=strategy_params
            )
            
            # 2. éªŒè¯æ–‡æ¡£
            valid_documents = DocumentValidator.validate_documents(documents)
            
            if not valid_documents:
                return {
                    "success": False,
                    "message": "ç›®å½•ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹",
                    "directory_path": str(directory_path)
                }
            
            # 3. è·å–æ–‡æ¡£æ‘˜è¦
            doc_summary = self.doc_processor.extract_metadata_summary(valid_documents)
            
            # 4. å‘é‡åŒ–å¹¶å­˜å‚¨
            result = await self.vector_manager.add_documents(valid_documents)
            
            # 5. ä¿å­˜å…ƒæ•°æ®ï¼ˆåŒ…å«ç­–ç•¥ä¿¡æ¯ï¼‰
            strategy_info = self.doc_processor.get_strategy_info()
            metadata = {
                "operation": "add_directory",
                "directory_path": str(directory_path),
                "recursive": recursive,
                "auto_strategy": auto_strategy,
                "chunking_strategy": strategy_info.get("name", "unknown"),
                "strategy_params": strategy_info.get("parameters", {}),
                "timestamp": datetime.now().isoformat(),
                "document_summary": doc_summary,
                "vector_result": result
            }
            
            self.save_processing_metadata(metadata)
            
            result.update({
                "directory_path": str(directory_path),
                "document_summary": doc_summary
            })
            
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "message": f"å¤„ç†ç›®å½•å¤±è´¥: {str(e)}",
                "directory_path": str(directory_path)
            }
            
            # ä¿å­˜é”™è¯¯å…ƒæ•°æ®
            strategy_info = self.doc_processor.get_strategy_info()
            error_metadata = {
                "operation": "add_directory",
                "directory_path": str(directory_path),
                "timestamp": datetime.now().isoformat(),
                "chunking_strategy": strategy_info.get("name", "unknown"),
                "error": str(e),
                "success": False
            }
            
            self.save_processing_metadata(error_metadata)
            
            return error_result
    
    async def search(self, query: str, k: int = 5, 
                    include_scores: bool = False) -> Dict[str, Any]:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            if include_scores:
                results = await self.vector_manager.search_with_scores(query, k)
                return {
                    "success": True,
                    "query": query,
                    "results": [
                        {
                            "content": doc.page_content,
                            "metadata": doc.metadata,
                            "score": score
                        }
                        for doc, score in results
                    ]
                }
            else:
                results = await self.vector_manager.search_similar(query, k)
                return {
                    "success": True,
                    "query": query,
                    "results": [
                        {
                            "content": doc.page_content,
                            "metadata": doc.metadata
                        }
                        for doc in results
                    ]
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"æœç´¢å¤±è´¥: {str(e)}",
                "query": query
            }
    
    def get_knowledge_base_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–å‘é‡å­˜å‚¨ç»Ÿè®¡
            vector_stats = self.vector_manager.get_collection_stats()
            
            # è·å–å¤„ç†å†å²
            processing_history = self.load_processing_metadata()
            
            # ç»Ÿè®¡å¤„ç†å†å²
            total_operations = len(processing_history.get("processing_history", []))
            successful_operations = sum(
                1 for op in processing_history.get("processing_history", [])
                if op.get("success", True)
            )
            
            return {
                "current_collection": self.current_collection,
                "vector_store_stats": vector_stats,
                "processing_stats": {
                    "total_operations": total_operations,
                    "successful_operations": successful_operations,
                    "success_rate": (successful_operations / total_operations * 100) 
                                  if total_operations > 0 else 0,
                    "last_updated": processing_history.get("last_updated")
                },
                "knowledge_base_path": str(self.knowledge_base_path),
                "metadata_path": str(self.metadata_path)
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "message": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
            }
    
    @staticmethod
    def list_knowledge_bases() -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“"""
        try:
            settings = get_settings()
            knowledge_base_root = Path(settings.knowledge_base_path)
            
            if not knowledge_base_root.exists():
                return []
            
            # è·å–æ‰€æœ‰å­ç›®å½•ä½œä¸ºçŸ¥è¯†åº“åˆ—è¡¨
            collections = []
            for item in knowledge_base_root.iterdir():
                if item.is_dir() and not item.name.startswith('.'):
                    collections.append(item.name)
            
            return sorted(collections)
            
        except Exception as e:
            print(f"âŒ è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    @staticmethod
    async def create_knowledge_base(collection_name: str, chunking_strategy: str = "recursive", strategy_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ›å»ºæ–°çš„çŸ¥è¯†åº“"""
        try:
            # éªŒè¯é›†åˆåç§°
            if not collection_name or not collection_name.strip():
                return {
                    "success": False,
                    "message": "çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©º"
                }
            
            # æ¸…ç†åç§°ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            import re
            clean_name = re.sub(r'[^\w\-_]', '_', collection_name.strip())
            
            if clean_name != collection_name.strip():
                print(f"âš ï¸ çŸ¥è¯†åº“åç§°å·²æ¸…ç†: '{collection_name}' -> '{clean_name}'")
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_collections = KnowledgeBaseManager.list_knowledge_bases()
            if clean_name in existing_collections:
                return {
                    "success": False,
                    "message": f"çŸ¥è¯†åº“ '{clean_name}' å·²å­˜åœ¨"
                }
            
            # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•ç»“æ„
            settings = get_settings()
            kb_path = Path(settings.knowledge_base_path) / clean_name
            kb_path.mkdir(parents=True, exist_ok=True)
            
            metadata_path = kb_path / "metadata"
            metadata_path.mkdir(exist_ok=True)
            
            # åˆ›å»ºçŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹æ¥åˆå§‹åŒ–å‘é‡å­˜å‚¨
            kb_manager = KnowledgeBaseManager(
                collection_name=clean_name,
                chunking_strategy=chunking_strategy,
                strategy_params=strategy_params
            )
            
            # æµ‹è¯•å‘é‡å­˜å‚¨è¿æ¥
            try:
                # å°è¯•è·å–ç»Ÿè®¡ä¿¡æ¯æ¥éªŒè¯é›†åˆæ˜¯å¦å¯ç”¨
                stats = kb_manager.vector_manager.get_collection_stats()
                print(f"âœ… çŸ¥è¯†åº“ '{clean_name}' å‘é‡å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as vector_e:
                print(f"âš ï¸ å‘é‡å­˜å‚¨åˆå§‹åŒ–è­¦å‘Š: {vector_e}")
            
            return {
                "success": True,
                "collection_name": clean_name,
                "message": f"çŸ¥è¯†åº“ '{clean_name}' åˆ›å»ºæˆåŠŸ",
                "path": str(kb_path)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}"
            }
    
    @staticmethod
    async def delete_knowledge_base(collection_name: str, confirm: bool = False) -> Dict[str, Any]:
        """åˆ é™¤çŸ¥è¯†åº“"""
        try:
            if not confirm:
                return {
                    "success": False,
                    "message": "è¯·ç¡®è®¤åˆ é™¤æ“ä½œï¼ˆè®¾ç½® confirm=Trueï¼‰"
                }
            
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
            existing_collections = KnowledgeBaseManager.list_knowledge_bases()
            if collection_name not in existing_collections:
                return {
                    "success": False,
                    "message": f"çŸ¥è¯†åº“ '{collection_name}' ä¸å­˜åœ¨"
                }
            
            settings = get_settings()
            kb_path = Path(settings.knowledge_base_path) / collection_name
            
            # åˆ é™¤Milvusé›†åˆ
            try:
                from pymilvus import connections, utility
                
                # è¿æ¥åˆ°Milvus
                connections.connect(
                    alias="temp_connection",
                    host=settings.milvus_host,
                    port=settings.milvus_port,
                    user=settings.milvus_user if settings.milvus_user else None,
                    password=settings.milvus_password if settings.milvus_password else None
                )
                
                # æ£€æŸ¥å¹¶åˆ é™¤é›†åˆ
                if utility.has_collection(collection_name, using="temp_connection"):
                    utility.drop_collection(collection_name, using="temp_connection")
                    print(f"âœ… Milvusé›†åˆ '{collection_name}' å·²åˆ é™¤")
                
                connections.disconnect("temp_connection")
                
            except Exception as milvus_e:
                print(f"âš ï¸ åˆ é™¤Milvusé›†åˆæ—¶å‡ºç°è­¦å‘Š: {milvus_e}")
            
            # åˆ é™¤æ–‡ä»¶ç³»ç»Ÿç›®å½•
            import shutil
            if kb_path.exists():
                shutil.rmtree(kb_path)
                print(f"âœ… çŸ¥è¯†åº“ç›®å½•å·²åˆ é™¤: {kb_path}")
            
            return {
                "success": True,
                "message": f"çŸ¥è¯†åº“ '{collection_name}' åˆ é™¤æˆåŠŸ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {str(e)}"
            }
    
    @staticmethod
    def switch_knowledge_base(collection_name: str) -> Dict[str, Any]:
        """åˆ‡æ¢å½“å‰çŸ¥è¯†åº“"""
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
            existing_collections = KnowledgeBaseManager.list_knowledge_bases()
            if collection_name not in existing_collections:
                return {
                    "success": False,
                    "message": f"çŸ¥è¯†åº“ '{collection_name}' ä¸å­˜åœ¨"
                }
            
            # æ›´æ–°ç¯å¢ƒå˜é‡ï¼ˆä»…åœ¨å½“å‰è¿›ç¨‹ä¸­æœ‰æ•ˆï¼‰
            import os
            os.environ["CURRENT_COLLECTION_NAME"] = collection_name
            
            return {
                "success": True,
                "message": f"å·²åˆ‡æ¢åˆ°çŸ¥è¯†åº“ '{collection_name}'",
                "collection_name": collection_name,
                "note": "æ­¤åˆ‡æ¢ä»…åœ¨å½“å‰è¿›ç¨‹ä¸­æœ‰æ•ˆ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"åˆ‡æ¢çŸ¥è¯†åº“å¤±è´¥: {str(e)}"
            }
    
    async def update_file(self, file_path: Union[str, Path], chunking_strategy: str = None, strategy_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ›´æ–°çŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶ï¼ˆæ”¯æŒä¸´æ—¶æŒ‡å®šåˆ†å—ç­–ç•¥ï¼‰"""
        try:
            print(f"ğŸ”„ æ›´æ–°æ–‡ä»¶: {file_path}")
            
            # 1. å¤„ç†æ–‡æ¡£ï¼ˆæ”¯æŒä¸´æ—¶ç­–ç•¥ï¼‰
            documents = self.doc_processor.process_file(
                file_path,
                chunking_strategy=chunking_strategy,
                strategy_params=strategy_params
            )
            
            # 2. éªŒè¯æ–‡æ¡£
            valid_documents = DocumentValidator.validate_documents(documents)
            
            if not valid_documents:
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹",
                    "file_path": str(file_path)
                }
            
            # 3. æ›´æ–°å‘é‡å­˜å‚¨
            result = await self.vector_manager.update_documents(valid_documents)
            
            # 4. ä¿å­˜å…ƒæ•°æ®ï¼ˆåŒ…å«ç­–ç•¥ä¿¡æ¯ï¼‰
            strategy_info = self.doc_processor.get_strategy_info()
            metadata = {
                "operation": "update_file",
                "file_path": str(file_path),
                "timestamp": datetime.now().isoformat(),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents),
                "chunking_strategy": strategy_info.get("name", "unknown"),
                "strategy_params": strategy_info.get("parameters", {}),
                "vector_result": result
            }
            
            self.save_processing_metadata(metadata)
            
            result.update({
                "file_path": str(file_path),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents)
            })
            
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"æ›´æ–°æ–‡ä»¶å¤±è´¥: {str(e)}",
                "file_path": str(file_path)
            }


# åˆ›å»ºå…¨å±€çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹ï¼ˆä½¿ç”¨é»˜è®¤åˆ†å—ç­–ç•¥ï¼‰
knowledge_base_manager = KnowledgeBaseManager()


def get_knowledge_base_manager() -> KnowledgeBaseManager:
    """è·å–å…¨å±€çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹"""
    return knowledge_base_manager