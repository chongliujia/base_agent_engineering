"""
çŸ¥è¯†åº“ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ–‡æ¡£å¤„ç†å’Œå‘é‡å­˜å‚¨
"""

import asyncio
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from datetime import datetime

from langchain_core.documents import Document

from .document_processor import DocumentProcessor, DocumentValidator
from .vector_store_manager import VectorStoreManager
from config.settings import get_settings


class KnowledgeBaseManager:
    """çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self.settings = get_settings()
        self.doc_processor = DocumentProcessor()
        self.vector_manager = VectorStoreManager()
        self.knowledge_base_path = Path(self.settings.knowledge_base_path)
        self.knowledge_base_path.mkdir(exist_ok=True)
        
        # åˆ›å»ºå…ƒæ•°æ®å­˜å‚¨ç›®å½•
        self.metadata_path = self.knowledge_base_path / "metadata"
        self.metadata_path.mkdir(exist_ok=True)
    
    def save_processing_metadata(self, metadata: Dict[str, Any], 
                               filename: str = "processing_log.json"):
        """ä¿å­˜å¤„ç†å…ƒæ•°æ®"""
        metadata_file = self.metadata_path / filename
        
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼ŒåŠ è½½ç°æœ‰æ•°æ®
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        else:
            existing_data = {"processing_history": []}
        
        # æ·»åŠ æ–°çš„å¤„ç†è®°å½•
        existing_data["processing_history"].append(metadata)
        existing_data["last_updated"] = datetime.now().isoformat()
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
    
    def load_processing_metadata(self, filename: str = "processing_log.json") -> Dict[str, Any]:
        """åŠ è½½å¤„ç†å…ƒæ•°æ®"""
        metadata_file = self.metadata_path / filename
        
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {"processing_history": []}
    
    async def add_file(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """æ·»åŠ å•ä¸ªæ–‡ä»¶åˆ°çŸ¥è¯†åº“"""
        try:
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path}")
            
            # 1. å¤„ç†æ–‡æ¡£
            documents = self.doc_processor.process_file(file_path)
            
            # 2. éªŒè¯æ–‡æ¡£
            valid_documents = DocumentValidator.validate_documents(documents)
            
            if not valid_documents:
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹",
                    "file_path": str(file_path)
                }
            
            # 3. å‘é‡åŒ–å¹¶å­˜å‚¨
            result = await self.vector_manager.add_documents(valid_documents)
            
            # 4. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "operation": "add_file",
                "file_path": str(file_path),
                "timestamp": datetime.now().isoformat(),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents),
                "vector_result": result
            }
            
            self.save_processing_metadata(metadata)
            
            result.update({
                "file_path": str(file_path),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents)
            })
            
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "message": f"å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}",
                "file_path": str(file_path)
            }
            
            # ä¿å­˜é”™è¯¯å…ƒæ•°æ®
            error_metadata = {
                "operation": "add_file",
                "file_path": str(file_path),
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "success": False
            }
            
            self.save_processing_metadata(error_metadata)
            
            return error_result
    
    async def add_directory(self, directory_path: Union[str, Path], 
                          recursive: bool = True) -> Dict[str, Any]:
        """æ·»åŠ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ°çŸ¥è¯†åº“"""
        try:
            print(f"ğŸ“ å¤„ç†ç›®å½•: {directory_path}")
            
            # 1. å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
            documents = self.doc_processor.process_directory(directory_path, recursive)
            
            # 2. éªŒè¯æ–‡æ¡£
            valid_documents = DocumentValidator.validate_documents(documents)
            
            if not valid_documents:
                return {
                    "success": False,
                    "message": "ç›®å½•ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹",
                    "directory_path": str(directory_path)
                }
            
            # 3. è·å–æ–‡æ¡£æ‘˜è¦
            doc_summary = self.doc_processor.extract_metadata_summary(valid_documents)
            
            # 4. å‘é‡åŒ–å¹¶å­˜å‚¨
            result = await self.vector_manager.add_documents(valid_documents)
            
            # 5. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "operation": "add_directory",
                "directory_path": str(directory_path),
                "recursive": recursive,
                "timestamp": datetime.now().isoformat(),
                "document_summary": doc_summary,
                "vector_result": result
            }
            
            self.save_processing_metadata(metadata)
            
            result.update({
                "directory_path": str(directory_path),
                "document_summary": doc_summary
            })
            
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "message": f"å¤„ç†ç›®å½•å¤±è´¥: {str(e)}",
                "directory_path": str(directory_path)
            }
            
            # ä¿å­˜é”™è¯¯å…ƒæ•°æ®
            error_metadata = {
                "operation": "add_directory",
                "directory_path": str(directory_path),
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "success": False
            }
            
            self.save_processing_metadata(error_metadata)
            
            return error_result
    
    async def search(self, query: str, k: int = 5, 
                    include_scores: bool = False) -> Dict[str, Any]:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            if include_scores:
                results = await self.vector_manager.search_with_scores(query, k)
                return {
                    "success": True,
                    "query": query,
                    "results": [
                        {
                            "content": doc.page_content,
                            "metadata": doc.metadata,
                            "score": score
                        }
                        for doc, score in results
                    ]
                }
            else:
                results = await self.vector_manager.search_similar(query, k)
                return {
                    "success": True,
                    "query": query,
                    "results": [
                        {
                            "content": doc.page_content,
                            "metadata": doc.metadata
                        }
                        for doc in results
                    ]
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"æœç´¢å¤±è´¥: {str(e)}",
                "query": query
            }
    
    def get_knowledge_base_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–å‘é‡å­˜å‚¨ç»Ÿè®¡
            vector_stats = self.vector_manager.get_collection_stats()
            
            # è·å–å¤„ç†å†å²
            processing_history = self.load_processing_metadata()
            
            # ç»Ÿè®¡å¤„ç†å†å²
            total_operations = len(processing_history.get("processing_history", []))
            successful_operations = sum(
                1 for op in processing_history.get("processing_history", [])
                if op.get("success", True)
            )
            
            return {
                "vector_store_stats": vector_stats,
                "processing_stats": {
                    "total_operations": total_operations,
                    "successful_operations": successful_operations,
                    "success_rate": (successful_operations / total_operations * 100) 
                                  if total_operations > 0 else 0,
                    "last_updated": processing_history.get("last_updated")
                },
                "knowledge_base_path": str(self.knowledge_base_path),
                "metadata_path": str(self.metadata_path)
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "message": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
            }
    
    async def update_file(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """æ›´æ–°çŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶"""
        try:
            print(f"ğŸ”„ æ›´æ–°æ–‡ä»¶: {file_path}")
            
            # 1. å¤„ç†æ–‡æ¡£
            documents = self.doc_processor.process_file(file_path)
            
            # 2. éªŒè¯æ–‡æ¡£
            valid_documents = DocumentValidator.validate_documents(documents)
            
            if not valid_documents:
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹",
                    "file_path": str(file_path)
                }
            
            # 3. æ›´æ–°å‘é‡å­˜å‚¨
            result = await self.vector_manager.update_documents(valid_documents)
            
            # 4. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "operation": "update_file",
                "file_path": str(file_path),
                "timestamp": datetime.now().isoformat(),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents),
                "vector_result": result
            }
            
            self.save_processing_metadata(metadata)
            
            result.update({
                "file_path": str(file_path),
                "total_chunks": len(documents),
                "valid_chunks": len(valid_documents)
            })
            
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"æ›´æ–°æ–‡ä»¶å¤±è´¥: {str(e)}",
                "file_path": str(file_path)
            }


# åˆ›å»ºå…¨å±€çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹
knowledge_base_manager = KnowledgeBaseManager()