"""
åŸºäºLangGraphçš„RAGå·¥ä½œæµ
"""

import time
import asyncio
from typing import Dict, Any, List, Optional
from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.documents import Document
from pydantic import BaseModel

from config.settings import get_model_config


class RAGState(BaseModel):
    """RAGå·¥ä½œæµçŠ¶æ€"""
    query: str
    messages: List[BaseMessage] = []
    documents: List[Document] = []
    web_results: List[Dict[str, Any]] = []
    context: str = ""
    response: str = ""
    metadata: Dict[str, Any] = {}
    
    class Config:
        arbitrary_types_allowed = True


class RAGWorkflow:
    """RAGå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self):
        self.model_config = get_model_config()
        self.chat_model = self.model_config.get_chat_model()
        self.embedding_model = self.model_config.get_embedding_model()
        self.vector_store = self.model_config.get_vector_store()
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºç®€åŒ–çš„LangGraphå·¥ä½œæµ - ç»Ÿä¸€å¹¶è¡Œæ£€ç´¢"""
        workflow = StateGraph(RAGState)
        
        # æ·»åŠ èŠ‚ç‚¹ - ç®€åŒ–ç‰ˆæœ¬
        workflow.add_node("query_analyzer", self.analyze_query)
        workflow.add_node("parallel_retrieval", self.parallel_retrieval)
        workflow.add_node("information_fusion", self.fuse_information)
        workflow.add_node("context_builder", self.build_context)
        workflow.add_node("response_generator", self.generate_response)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("query_analyzer")
        
        # ç®€åŒ–çš„çº¿æ€§æµç¨‹
        workflow.add_edge("query_analyzer", "parallel_retrieval")
        workflow.add_edge("parallel_retrieval", "information_fusion")
        workflow.add_edge("information_fusion", "context_builder")
        workflow.add_edge("context_builder", "response_generator")
        workflow.add_edge("response_generator", END)
        
        return workflow.compile()
    
    async def analyze_query(self, state: RAGState) -> RAGState:
        """åˆ†ææŸ¥è¯¢æ„å›¾å’Œç‰¹å¾"""
        # ç®€åŒ–çš„æŸ¥è¯¢åˆ†æï¼Œä¸ºå¹¶è¡Œæ£€ç´¢åšå‡†å¤‡
        query = state.query
        
        # åŸºç¡€æŸ¥è¯¢ç‰¹å¾åˆ†æ
        state.metadata.update({
            "query_length": len(query),
            "has_question_mark": "?" in query,
            "has_keywords": any(kw in query.lower() for kw in ["ä»€ä¹ˆ", "å¦‚ä½•", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ"]),
            "timestamp": time.time()
        })
        
        print(f"ğŸ” æŸ¥è¯¢åˆ†æ: {query[:30]}{'...' if len(query) > 30 else ''}")
        return state
    
    async def parallel_retrieval(self, state: RAGState) -> RAGState:
        """æ ¸å¿ƒå¹¶è¡Œæ£€ç´¢ - åŒæ—¶æ‰§è¡ŒçŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢"""
        import asyncio
        
        print("ğŸ”„ å¹¶è¡Œæ£€ç´¢ä¸­...")
        start_time = time.time()
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        knowledge_task = self._retrieve_knowledge_task(state)
        web_task = self._search_web_task(state)
        
        try:
            # å¹¶è¡Œæ‰§è¡Œï¼Œå…è®¸éƒ¨åˆ†å¤±è´¥
            knowledge_results, web_results = await asyncio.gather(
                knowledge_task, 
                web_task,
                return_exceptions=True
            )
            
            # ç»Ÿè®¡æˆåŠŸçš„æ£€ç´¢æº
            successful_sources = []
            total_results = 0
            
            # å¤„ç†çŸ¥è¯†åº“æ£€ç´¢ç»“æœ
            if isinstance(knowledge_results, Exception):
                print(f"ğŸ“š çŸ¥è¯†åº“: âŒ {str(knowledge_results)[:50]}...")
                state.metadata["knowledge_error"] = str(knowledge_results)
                state.metadata["knowledge_retrieved"] = 0
            else:
                state.documents.extend(knowledge_results)
                kb_count = len(knowledge_results)
                state.metadata["knowledge_retrieved"] = kb_count
                total_results += kb_count
                if kb_count > 0:
                    successful_sources.append("çŸ¥è¯†åº“")
                    print(f"ğŸ“š çŸ¥è¯†åº“: âœ… {kb_count}ä¸ªæ–‡æ¡£")
            
            # å¤„ç†ç½‘ç»œæœç´¢ç»“æœ
            if isinstance(web_results, Exception):
                print(f"ğŸŒ ç½‘ç»œæœç´¢: âŒ {str(web_results)[:50]}...")
                state.metadata["web_error"] = str(web_results)
                state.metadata["web_retrieved"] = 0
            else:
                state.web_results.extend(web_results)
                web_count = len(web_results)
                state.metadata["web_retrieved"] = web_count
                total_results += web_count
                if web_count > 0:
                    successful_sources.append("ç½‘ç»œæœç´¢")
                    print(f"ğŸŒ ç½‘ç»œæœç´¢: âœ… {web_count}ä¸ªç»“æœ")
            
            # è®°å½•æ£€ç´¢ç»Ÿè®¡
            parallel_time = time.time() - start_time
            state.metadata.update({
                "parallel_retrieval_time": round(parallel_time, 2),
                "total_results": total_results,
                "successful_sources": successful_sources,
                "retrieval_mode": self._determine_actual_mode(successful_sources)
            })
            
            # è¾“å‡ºæ£€ç´¢æ‘˜è¦
            if successful_sources:
                sources_str = " + ".join(successful_sources)
                print(f"âš¡ æ£€ç´¢å®Œæˆ: {sources_str} ({total_results}ä¸ªç»“æœ, {parallel_time:.2f}s)")
            else:
                print(f"âš ï¸ æ£€ç´¢å®Œæˆ: æ— å¯ç”¨ç»“æœ ({parallel_time:.2f}s)")
            
        except Exception as e:
            state.metadata["parallel_error"] = str(e)
            print(f"âŒ å¹¶è¡Œæ£€ç´¢ç³»ç»Ÿé”™è¯¯: {e}")
        
        return state
    
    def _determine_actual_mode(self, successful_sources: list) -> str:
        """æ ¹æ®å®é™…æ£€ç´¢ç»“æœç¡®å®šæ‰§è¡Œæ¨¡å¼"""
        if not successful_sources:
            return "æ— ç»“æœ"
        elif len(successful_sources) == 2:
            return "æ··åˆæ¨¡å¼"
        elif "çŸ¥è¯†åº“" in successful_sources:
            return "çŸ¥è¯†åº“æ¨¡å¼"
        elif "ç½‘ç»œæœç´¢" in successful_sources:
            return "ç½‘ç»œæ¨¡å¼"
        else:
            return "æœªçŸ¥æ¨¡å¼"
    
    async def _retrieve_knowledge_task(self, state: RAGState) -> List:
        """çŸ¥è¯†åº“æ£€ç´¢ä»»åŠ¡ - ç”¨äºå¹¶è¡Œæ‰§è¡Œ"""
        try:
            # ä½¿ç”¨çŸ¥è¯†åº“ç®¡ç†å™¨æ¥é¿å…å¼‚æ­¥å¾ªç¯é—®é¢˜
            from src.knowledge_base.knowledge_base_manager import get_knowledge_base_manager
            
            kb_manager = get_knowledge_base_manager()
            result = await kb_manager.search(state.query, k=3, include_scores=False)
            
            if result.get("success"):
                # è½¬æ¢ä¸ºDocumentå¯¹è±¡
                docs = []
                for item in result.get("results", []):
                    from langchain_core.documents import Document
                    doc = Document(
                        page_content=item["content"], 
                        metadata=item["metadata"]
                    )
                    docs.append(doc)
                return docs
            else:
                raise Exception(result.get("message", "çŸ¥è¯†åº“æœç´¢å¤±è´¥"))
                
        except Exception as e:
            # æŠ›å‡ºå¼‚å¸¸ä¾›å¹¶è¡Œå¤„ç†å™¨æ•è·
            raise e
    
    async def _search_web_task(self, state: RAGState) -> List:
        """ç½‘ç»œæœç´¢ä»»åŠ¡ - ç”¨äºå¹¶è¡Œæ‰§è¡Œ"""
        try:
            from src.search.web_search import search_web
            
            web_results = await search_web(
                query=state.query,
                max_results=3,  # é™åˆ¶ä¸º3ä¸ªç»“æœ
                search_config={
                    "search_depth": "advanced",
                    "exclude_domains": ["pinterest.com", "twitter.com", "instagram.com"]
                }
            )
            
            return web_results if web_results else []
        except Exception as e:
            # æŠ›å‡ºå¼‚å¸¸ä¾›å¹¶è¡Œå¤„ç†å™¨æ•è·
            raise e
    
    async def fuse_information(self, state: RAGState) -> RAGState:
        """èåˆä¿¡æ¯"""
        # åˆå¹¶çŸ¥è¯†åº“æ–‡æ¡£å’Œç½‘ç»œæœç´¢ç»“æœ
        all_sources = []
        
        # æ·»åŠ çŸ¥è¯†åº“æ–‡æ¡£
        for doc in state.documents:
            all_sources.append({
                "content": doc.page_content,
                "source": "knowledge_base",
                "metadata": doc.metadata
            })
        
        # æ·»åŠ ç½‘ç»œæœç´¢ç»“æœ
        for result in state.web_results:
            all_sources.append({
                "content": result["content"],
                "source": "web_search",
                "metadata": {"url": result["url"], "title": result["title"]}
            })
        
        state.metadata["total_sources"] = len(all_sources)
        state.metadata["fused_sources"] = all_sources
        
        return state
    
    async def build_context(self, state: RAGState) -> RAGState:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        sources = state.metadata.get("fused_sources", [])
        
        # åˆ†åˆ«æ„å»ºçŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢ä¸Šä¸‹æ–‡
        knowledge_sources = [s for s in sources if s['source'] == 'knowledge_base']
        web_sources = [s for s in sources if s['source'] == 'web_search']
        
        # æ„å»ºçŸ¥è¯†åº“ä¸Šä¸‹æ–‡
        knowledge_context = ""
        if knowledge_sources:
            kb_parts = []
            for i, source in enumerate(knowledge_sources[:3]):
                metadata = source.get('metadata', {})
                source_info = f"æ–‡æ¡£: {metadata.get('filename', 'æœªçŸ¥')}"
                kb_parts.append(f"{source_info}\nå†…å®¹: {source['content'][:500]}")
            knowledge_context = "\n\n".join(kb_parts)
        
        # æ„å»ºç½‘ç»œæœç´¢ä¸Šä¸‹æ–‡  
        web_context = ""
        if web_sources:
            web_parts = []
            for i, source in enumerate(web_sources[:3]):
                metadata = source.get('metadata', {})
                source_info = f"æ ‡é¢˜: {metadata.get('title', 'æœªçŸ¥')}\né“¾æ¥: {metadata.get('url', 'æœªçŸ¥')}"
                web_parts.append(f"{source_info}\nå†…å®¹: {source['content'][:500]}")
            web_context = "\n\n".join(web_parts)
        
        # ä¿å­˜ç»“æ„åŒ–ä¸Šä¸‹æ–‡
        state.metadata["knowledge_context"] = knowledge_context
        state.metadata["web_context"] = web_context
        
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆå‘åå…¼å®¹ï¼‰
        all_parts = []
        if knowledge_context:
            all_parts.append(f"=== çŸ¥è¯†åº“ä¿¡æ¯ ===\n{knowledge_context}")
        if web_context:
            all_parts.append(f"=== ç½‘ç»œæœç´¢ä¿¡æ¯ ===\n{web_context}")
        
        state.context = "\n\n".join(all_parts)
        return state
    
    async def generate_response(self, state: RAGState, stream_callback=None) -> RAGState:
        """æ™ºèƒ½å›ç­”ç”Ÿæˆ - åŸºäºå®é™…æ£€ç´¢ç»“æœé€‰æ‹©æç¤ºè¯"""
        try:
            from src.prompts.prompt_manager import render_prompt, get_prompt_manager
            
            # è·å–æç¤ºè¯ç®¡ç†å™¨å¹¶æ£€æµ‹è¯­è¨€
            prompt_manager = get_prompt_manager()
            
            # æ ¹æ®å®é™…æ£€ç´¢æ¨¡å¼é€‰æ‹©æç¤ºè¯ç­–ç•¥
            retrieval_mode = state.metadata.get("retrieval_mode", "æ··åˆæ¨¡å¼") 
            knowledge_context = state.metadata.get("knowledge_context", "")
            web_context = state.metadata.get("web_context", "")
            
            # æ™ºèƒ½æç¤ºè¯é€‰æ‹©ï¼ˆè¯­è¨€è‡ªé€‚åº”ï¼‰
            if retrieval_mode == "çŸ¥è¯†åº“æ¨¡å¼" and knowledge_context:
                # çŸ¥è¯†åº“æ¨¡å¼æš‚æ—¶ä¿æŒåŸæœ‰é€»è¾‘
                prompt = render_prompt("knowledge_only", 
                                     knowledge_context=knowledge_context,
                                     query=state.query)
                prompt_type = "knowledge_only"
            elif retrieval_mode == "ç½‘ç»œæ¨¡å¼" and web_context:
                # ç½‘ç»œæ¨¡å¼æš‚æ—¶ä¿æŒåŸæœ‰é€»è¾‘  
                prompt = render_prompt("web_only",
                                     web_context=web_context, 
                                     query=state.query)
                prompt_type = "web_only"
            elif retrieval_mode == "æ··åˆæ¨¡å¼":
                # ä½¿ç”¨è¯­è¨€è‡ªé€‚åº”çš„RAGæç¤ºè¯
                adaptive_template = prompt_manager.select_adaptive_prompt(state.query)
                prompt = render_prompt(adaptive_template,
                                     knowledge_context=knowledge_context or "No relevant knowledge base information available",
                                     web_context=web_context or "No relevant web search information available", 
                                     query=state.query)
                prompt_type = adaptive_template
            else:
                # æ— æ£€ç´¢ç»“æœçš„å›ç­”
                prompt = f"""ä½œä¸ºAIåŠ©æ‰‹ï¼Œæˆ‘éœ€è¦åŸºäºç°æœ‰çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{state.query}

ç”±äºå½“å‰æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„çŸ¥è¯†åº“æ–‡æ¡£æˆ–ç½‘ç»œæœç´¢ç»“æœï¼Œæˆ‘å°†åŸºäºè®­ç»ƒæ•°æ®ä¸­çš„çŸ¥è¯†æ¥å›ç­”ï¼Œä½†è¯·æ³¨æ„ä¿¡æ¯å¯èƒ½ä¸æ˜¯æœ€æ–°çš„ã€‚

å›ç­”ï¼š"""
                prompt_type = "fallback"

            # ä½¿ç”¨èŠå¤©æ¨¡å‹ç”Ÿæˆå›ç­”
            messages = [HumanMessage(content=prompt)]
            
            if stream_callback:
                # æµå¼è¾“å‡ºæ¨¡å¼
                full_response = ""
                async for chunk in self.chat_model.astream(messages):
                    if hasattr(chunk, 'content') and chunk.content:
                        full_response += chunk.content
                        if stream_callback:
                            if asyncio.iscoroutinefunction(stream_callback):
                                await stream_callback(chunk.content)
                            else:
                                stream_callback("chunk", chunk.content)
                
                state.response = full_response
            else:
                # éæµå¼è¾“å‡ºæ¨¡å¼
                response = await self.chat_model.ainvoke(messages)
                state.response = response.content
            
            state.messages.append(HumanMessage(content=state.query))
            state.messages.append(AIMessage(content=state.response))
            
            # è®°å½•ç”Ÿæˆä¿¡æ¯
            state.metadata.update({
                "prompt_type_used": prompt_type,
                "response_length": len(state.response),
                "generation_successful": True
            })
            
            print(f"ğŸ’¬ å›ç­”ç”Ÿæˆ: {prompt_type} ({len(state.response)}å­—ç¬¦)")
            
        except Exception as e:
            state.response = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            state.metadata.update({
                "generation_error": str(e),
                "generation_successful": False
            })
            print(f"âŒ å›ç­”ç”Ÿæˆå¤±è´¥: {e}")
        
        return state
    
    async def run(self, query: str, stream_callback=None) -> RAGState:
        """è¿è¡ŒRAGå·¥ä½œæµ"""
        initial_state = RAGState(query=query)
        
        # ç”±äºLangGraphä¸ç›´æ¥æ”¯æŒæµå¼å›è°ƒï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ‰§è¡Œæ­¥éª¤
        if stream_callback:
            # æ‰‹åŠ¨æ‰§è¡Œå·¥ä½œæµæ­¥éª¤ä»¥æ”¯æŒæµå¼è¾“å‡º
            if callable(stream_callback):
                stream_callback("analysis")
            state = await self.analyze_query(initial_state)
            
            if callable(stream_callback):
                stream_callback("retrieval")
            state = await self.parallel_retrieval(state)
            
            if callable(stream_callback):
                stream_callback("fusion")
            state = await self.fuse_information(state)
            
            if callable(stream_callback):
                stream_callback("context")
            state = await self.build_context(state)
            
            if callable(stream_callback):
                stream_callback("generation")
            state = await self.generate_response(state, stream_callback)
            return state
        else:
            # ä½¿ç”¨æ ‡å‡†å·¥ä½œæµ
            final_state = await self.workflow.ainvoke(initial_state)
            return final_state


# åˆ›å»ºå…¨å±€å·¥ä½œæµå®ä¾‹
rag_workflow = RAGWorkflow()