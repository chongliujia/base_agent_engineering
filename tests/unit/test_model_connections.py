"""
æ¨¡å‹è¿æ¥æµ‹è¯• - ä½¿ç”¨é…ç½®æ–‡ä»¶æµ‹è¯•æ‰€æœ‰æ¨¡å‹è¿æ¥
"""

import os
import pytest
import asyncio
from unittest.mock import patch, MagicMock
from typing import Dict, Any

from config.settings import get_model_config, get_settings
from src.reranking.dashscope_rerank import DashScopeRerank


class TestModelConnections:
    """æ¨¡å‹è¿æ¥æµ‹è¯•ç±»"""
    
    @classmethod
    def setup_class(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ–"""
        cls.model_config = get_model_config()
        cls.settings = get_settings()
        
        # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
        cls.has_openai_key = bool(os.getenv("OPENAI_API_KEY"))
        cls.has_dashscope_key = bool(os.getenv("DASHSCOPE_API_KEY"))
    
    def test_model_config_loading(self):
        """æµ‹è¯•æ¨¡å‹é…ç½®åŠ è½½"""
        # æµ‹è¯•é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡®åŠ è½½
        assert self.model_config._config is not None
        assert "chat_models" in self.model_config._config
        assert "embedding_models" in self.model_config._config
        assert "reranking_models" in self.model_config._config
        assert "default_models" in self.model_config._config
        
        # æµ‹è¯•é»˜è®¤æ¨¡å‹é…ç½®
        default_models = self.model_config._config["default_models"]
        assert default_models["chat"] == "primary"
        assert default_models["embedding"] == "primary"
        assert default_models["reranking"] == "primary"
    
    def test_chat_model_config(self):
        """æµ‹è¯•èŠå¤©æ¨¡å‹é…ç½®"""
        chat_models = self.model_config._config["chat_models"]
        
        # æµ‹è¯•primaryæ¨¡å‹é…ç½®
        assert "primary" in chat_models
        primary_config = chat_models["primary"]
        # æ ¹æ®å®é™…é…ç½®æ–‡ä»¶è°ƒæ•´æœŸæœ›å€¼
        print(f"Primary model name: {primary_config['name']}")
        assert primary_config["name"] in ["gpt-4", "qwen-plus"]  # æ”¯æŒä¸¤ç§å¯èƒ½çš„é…ç½®
        assert primary_config["provider"] == "langchain_openai"
        # API key å­—æ®µå¯èƒ½æ˜¯ç¯å¢ƒå˜é‡åæˆ–ç›´æ¥çš„key
        assert "api_key_env" in primary_config
        
        # æµ‹è¯•fallbackæ¨¡å‹é…ç½®
        assert "fallback" in chat_models
        fallback_config = chat_models["fallback"]
        print(f"Fallback model name: {fallback_config['name']}")
        assert fallback_config["name"] in ["gpt-3.5-turbo", "qwen-plus"]  # æ”¯æŒä¸¤ç§å¯èƒ½çš„é…ç½®
        assert fallback_config["provider"] == "langchain_openai"
    
    def test_embedding_model_config(self):
        """æµ‹è¯•åµŒå…¥æ¨¡å‹é…ç½®"""
        embedding_models = self.model_config._config["embedding_models"]
        
        # æµ‹è¯•primaryæ¨¡å‹é…ç½®
        assert "primary" in embedding_models
        primary_config = embedding_models["primary"]
        print(f"Primary embedding model name: {primary_config['name']}")
        assert primary_config["name"] in ["text-embedding-3-large", "text-embedding-v4"]
        assert primary_config["provider"] == "langchain_openai"
        # ç»´åº¦å¯èƒ½ä¸åŒï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºåˆç†æ•°å€¼
        dimensions = primary_config["parameters"]["dimensions"]
        assert dimensions in [1536, 2048, 3072]  # å¸¸è§çš„åµŒå…¥ç»´åº¦
        
        # æµ‹è¯•fallbackæ¨¡å‹é…ç½®
        assert "fallback" in embedding_models
        fallback_config = embedding_models["fallback"]
        print(f"Fallback embedding model name: {fallback_config['name']}")
        assert fallback_config["name"] in ["text-embedding-3-small", "text-embedding-v4"]
        fallback_dimensions = fallback_config["parameters"]["dimensions"]
        assert fallback_dimensions in [1536, 2048, 3072]
    
    def test_reranking_model_config(self):
        """æµ‹è¯•é‡æ’åºæ¨¡å‹é…ç½®"""
        reranking_models = self.model_config._config["reranking_models"]
        
        # æµ‹è¯•primaryæ¨¡å‹é…ç½®
        assert "primary" in reranking_models
        primary_config = reranking_models["primary"]
        assert primary_config["name"] == "gte-rerank-v2"
        assert primary_config["provider"] == "dashscope"
        assert primary_config["api_key_env"] == "DASHSCOPE_API_KEY"
    
    @pytest.mark.skipif(not os.getenv("OPENAI_API_KEY"), reason="OPENAI_API_KEY not set")
    def test_chat_model_connection(self):
        """æµ‹è¯•èŠå¤©æ¨¡å‹è¿æ¥"""
        try:
            # æµ‹è¯•primaryæ¨¡å‹
            chat_model = self.model_config.get_chat_model("primary")
            assert chat_model is not None
            
            # ç®€å•çš„è¿æ¥æµ‹è¯•
            response = chat_model.invoke([{"role": "user", "content": "Hello"}])
            assert response is not None
            assert hasattr(response, 'content')
            
            print(f"âœ… èŠå¤©æ¨¡å‹è¿æ¥æˆåŠŸ: {response.content[:50]}...")
            
        except Exception as e:
            pytest.fail(f"èŠå¤©æ¨¡å‹è¿æ¥å¤±è´¥: {str(e)}")
    
    @pytest.mark.skipif(not os.getenv("OPENAI_API_KEY"), reason="OPENAI_API_KEY not set")
    def test_embedding_model_connection(self):
        """æµ‹è¯•åµŒå…¥æ¨¡å‹è¿æ¥"""
        try:
            # æµ‹è¯•primaryæ¨¡å‹
            embedding_model = self.model_config.get_embedding_model("primary")
            assert embedding_model is not None
            
            # ç®€å•çš„åµŒå…¥æµ‹è¯•
            test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
            embeddings = embedding_model.embed_query(test_text)
            assert embeddings is not None
            assert len(embeddings) == 3072  # text-embedding-3-largeçš„ç»´åº¦
            
            print(f"âœ… åµŒå…¥æ¨¡å‹è¿æ¥æˆåŠŸ: ç”Ÿæˆäº† {len(embeddings)} ç»´å‘é‡")
            
        except Exception as e:
            pytest.fail(f"åµŒå…¥æ¨¡å‹è¿æ¥å¤±è´¥: {str(e)}")
    
    @pytest.mark.skipif(not os.getenv("DASHSCOPE_API_KEY"), reason="DASHSCOPE_API_KEY not set")
    def test_reranking_model_connection(self):
        """æµ‹è¯•é‡æ’åºæ¨¡å‹è¿æ¥"""
        try:
            # æµ‹è¯•primaryæ¨¡å‹
            reranking_model = self.model_config.get_reranking_model("primary")
            assert reranking_model is not None
            assert isinstance(reranking_model, DashScopeRerank)
            
            # ç®€å•çš„é‡æ’åºæµ‹è¯•
            query = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
            documents = [
                "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
                "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
                "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ"
            ]
            
            results = reranking_model.rerank(query, documents, top_n=3)
            assert results is not None
            assert len(results) <= 3
            assert all("relevance_score" in result for result in results)
            assert all("document" in result for result in results)
            
            print(f"âœ… é‡æ’åºæ¨¡å‹è¿æ¥æˆåŠŸ: å¤„ç†äº† {len(results)} ä¸ªæ–‡æ¡£")
            for i, result in enumerate(results):
                print(f"   {i+1}. [åˆ†æ•°: {result['relevance_score']:.4f}] {result['document'][:30]}...")
            
        except Exception as e:
            pytest.fail(f"é‡æ’åºæ¨¡å‹è¿æ¥å¤±è´¥: {str(e)}")
    
    def test_vector_store_config(self):
        """æµ‹è¯•å‘é‡å­˜å‚¨é…ç½®"""
        vector_stores = self.model_config._config["vector_stores"]
        
        # æµ‹è¯•primaryé…ç½®
        assert "primary" in vector_stores
        primary_config = vector_stores["primary"]
        assert primary_config["name"] == "milvus"
        assert primary_config["provider"] == "langchain_milvus"
        assert "connection_args" in primary_config
    
    def test_model_fallback_config(self):
        """æµ‹è¯•æ¨¡å‹fallbacké…ç½®"""
        model_switching = self.model_config._config["model_switching"]
        
        assert model_switching["enabled"] is True
        assert "fallback_chain" in model_switching
        
        fallback_chain = model_switching["fallback_chain"]
        assert "chat" in fallback_chain
        assert "embedding" in fallback_chain
        assert fallback_chain["chat"] == ["primary", "fallback"]
        assert fallback_chain["embedding"] == ["primary", "fallback"]
    
    def test_model_with_fallback(self):
        """æµ‹è¯•å¸¦fallbackçš„æ¨¡å‹è·å–"""
        # æµ‹è¯•èŠå¤©æ¨¡å‹fallbackï¼ˆä¸éœ€è¦å®é™…APIè°ƒç”¨ï¼‰
        try:
            # è¿™é‡Œä¸ä¼šçœŸæ­£è°ƒç”¨APIï¼Œåªæ˜¯æµ‹è¯•é…ç½®åŠ è½½
            available_models = self.model_config.list_available_models("chat")
            assert "chat" in available_models
            assert "primary" in available_models["chat"]
            assert "fallback" in available_models["chat"]
            
            # æµ‹è¯•åµŒå…¥æ¨¡å‹
            available_models = self.model_config.list_available_models("embedding")
            assert "embedding" in available_models
            assert "primary" in available_models["embedding"]
            assert "fallback" in available_models["embedding"]
            
            print("âœ… æ¨¡å‹fallbacké…ç½®æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            pytest.fail(f"æ¨¡å‹fallbacké…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")
    
    @pytest.mark.asyncio
    async def test_async_reranking(self):
        """æµ‹è¯•å¼‚æ­¥é‡æ’åºåŠŸèƒ½"""
        if not os.getenv("DASHSCOPE_API_KEY"):
            pytest.skip("DASHSCOPE_API_KEY not set")
        
        try:
            reranking_model = self.model_config.get_reranking_model("primary")
            
            query = "äººå·¥æ™ºèƒ½çš„åº”ç”¨"
            documents = [
                "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨",
                "ä»Šå¤©çš„åˆé¤å¾ˆç¾å‘³",
                "æœºå™¨å­¦ä¹ ç®—æ³•ä¸æ–­å‘å±•"
            ]
            
            # æµ‹è¯•å¼‚æ­¥é‡æ’åº
            results = await reranking_model.arerank(query, documents, top_n=2)
            assert results is not None
            assert len(results) <= 2
            
            print(f"âœ… å¼‚æ­¥é‡æ’åºæµ‹è¯•é€šè¿‡: å¤„ç†äº† {len(results)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            pytest.fail(f"å¼‚æ­¥é‡æ’åºæµ‹è¯•å¤±è´¥: {str(e)}")
    
    def test_model_info_retrieval(self):
        """æµ‹è¯•æ¨¡å‹ä¿¡æ¯è·å–"""
        try:
            # æµ‹è¯•è·å–èŠå¤©æ¨¡å‹ä¿¡æ¯
            chat_info = self.model_config.get_model_info("chat", "primary")
            assert chat_info["name"] == "gpt-4"
            assert chat_info["provider"] == "langchain_openai"
            
            # æµ‹è¯•è·å–åµŒå…¥æ¨¡å‹ä¿¡æ¯
            embedding_info = self.model_config.get_model_info("embedding", "primary")
            assert embedding_info["name"] == "text-embedding-3-large"
            assert embedding_info["provider"] == "langchain_openai"
            
            # æµ‹è¯•è·å–é‡æ’åºæ¨¡å‹ä¿¡æ¯
            reranking_info = self.model_config.get_model_info("reranking", "primary")
            assert reranking_info["name"] == "gte-rerank-v2"
            assert reranking_info["provider"] == "dashscope"
            
            print("âœ… æ¨¡å‹ä¿¡æ¯è·å–æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            pytest.fail(f"æ¨¡å‹ä¿¡æ¯è·å–æµ‹è¯•å¤±è´¥: {str(e)}")
    
    def test_performance_config(self):
        """æµ‹è¯•æ€§èƒ½é…ç½®"""
        performance_config = self.model_config.get_performance_config()
        
        assert "max_concurrent_requests" in performance_config
        assert "cache" in performance_config
        assert "batch_processing" in performance_config
        
        max_concurrent = performance_config["max_concurrent_requests"]
        assert max_concurrent["chat"] == 10
        assert max_concurrent["embedding"] == 20
        assert max_concurrent["reranking"] == 15
        
        print("âœ… æ€§èƒ½é…ç½®æµ‹è¯•é€šè¿‡")
    
    def test_monitoring_config(self):
        """æµ‹è¯•ç›‘æ§é…ç½®"""
        monitoring_config = self.model_config.get_monitoring_config()
        
        assert "logging" in monitoring_config
        assert "cost_tracking" in monitoring_config
        assert "performance_tracking" in monitoring_config
        
        cost_tracking = monitoring_config["cost_tracking"]
        assert cost_tracking["enabled"] is True
        assert cost_tracking["daily_limit"] == 50.0
        
        print("âœ… ç›‘æ§é…ç½®æµ‹è¯•é€šè¿‡")


def run_connection_tests():
    """è¿è¡Œè¿æ¥æµ‹è¯•çš„ä¾¿æ·å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ¨¡å‹è¿æ¥æµ‹è¯•...")
    print("="*60)
    
    test_instance = TestModelConnections()
    test_instance.setup_class()
    
    # åŸºç¡€é…ç½®æµ‹è¯•
    print("ğŸ“‹ æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½...")
    test_instance.test_model_config_loading()
    test_instance.test_chat_model_config()
    test_instance.test_embedding_model_config()
    test_instance.test_reranking_model_config()
    print("âœ… é…ç½®æ–‡ä»¶æµ‹è¯•é€šè¿‡\n")
    
    # APIè¿æ¥æµ‹è¯•
    print("ğŸ”Œ æµ‹è¯•APIè¿æ¥...")
    
    if os.getenv("OPENAI_API_KEY"):
        print("ğŸ”‘ æ£€æµ‹åˆ° OPENAI_API_KEYï¼Œæµ‹è¯•OpenAIè¿æ¥...")
        try:
            test_instance.test_chat_model_connection()
            test_instance.test_embedding_model_connection()
        except Exception as e:
            print(f"âŒ OpenAIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("âš ï¸  æœªè®¾ç½® OPENAI_API_KEYï¼Œè·³è¿‡OpenAIè¿æ¥æµ‹è¯•")
    
    if os.getenv("DASHSCOPE_API_KEY"):
        print("ğŸ”‘ æ£€æµ‹åˆ° DASHSCOPE_API_KEYï¼Œæµ‹è¯•DashScopeè¿æ¥...")
        try:
            test_instance.test_reranking_model_connection()
        except Exception as e:
            print(f"âŒ DashScopeè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("âš ï¸  æœªè®¾ç½® DASHSCOPE_API_KEYï¼Œè·³è¿‡DashScopeè¿æ¥æµ‹è¯•")
    
    print("\nğŸ¯ æµ‹è¯•å…¶ä»–åŠŸèƒ½...")
    test_instance.test_vector_store_config()
    test_instance.test_model_fallback_config()
    test_instance.test_model_with_fallback()
    test_instance.test_model_info_retrieval()
    test_instance.test_performance_config()
    test_instance.test_monitoring_config()
    
    print("\n" + "="*60)
    print("ğŸ‰ æ¨¡å‹è¿æ¥æµ‹è¯•å®Œæˆï¼")
    
    # æ˜¾ç¤ºç¯å¢ƒå˜é‡çŠ¶æ€
    print("\nğŸ“Š ç¯å¢ƒå˜é‡çŠ¶æ€:")
    print(f"   OPENAI_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'âŒ æœªè®¾ç½®'}")
    print(f"   DASHSCOPE_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('DASHSCOPE_API_KEY') else 'âŒ æœªè®¾ç½®'}")
    print(f"   LANGSMITH_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('LANGSMITH_API_KEY') else 'âŒ æœªè®¾ç½®'}")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    run_connection_tests()