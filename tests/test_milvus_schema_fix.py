#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„ Milvus schema é…ç½®
"""

import os
import sys
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.settings import get_model_config
from src.knowledge_base.vector_store_manager import VectorStoreManager
from src.utils.async_utils import safe_async_run, is_async_context
from langchain_core.documents import Document

async def test_milvus_schema_fix():
    """æµ‹è¯•ä¿®å¤åçš„ Milvus schema é…ç½®"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ä¿®å¤åçš„ Milvus schema...")
    
    # æ£€æŸ¥ API Key
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        return False
    
    print(f"ğŸ”‘ API Key: {api_key[:10]}...")
    
    try:
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
        print("ğŸ” åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨...")
        vector_manager = VectorStoreManager()
        print("âœ… å‘é‡å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£ï¼ˆåŒ…å«å®Œæ•´çš„ metadata å­—æ®µï¼Œä¸ document_processor.py ä¿æŒä¸€è‡´ï¼‰
        test_docs = [
            Document(
                page_content="è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼ŒåŒ…å«äººå·¥æ™ºèƒ½çš„åŸºç¡€çŸ¥è¯†ã€‚äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
                metadata={
                    "source": "test1.txt",
                    "filename": "test1.txt",
                    "file_type": ".txt",
                    "file_size": 1024,
                    "file_hash": "abc123def456",
                    "created_time": "2024-01-01T00:00:00",
                    "modified_time": "2024-01-01T00:00:00",
                    "processed_time": "2024-01-01T00:00:00",
                    "chunk_id": 0,
                    "chunk_size": 89,
                    "split_time": "2024-01-01T00:00:00"
                }
            ),
            Document(
                page_content="è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œè®¨è®ºæœºå™¨å­¦ä¹ çš„åº”ç”¨ã€‚æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
                metadata={
                    "source": "test2.txt", 
                    "filename": "test2.txt",
                    "file_type": ".txt",
                    "file_size": 2048,
                    "file_hash": "def456ghi789",
                    "created_time": "2024-01-01T00:00:00",
                    "modified_time": "2024-01-01T00:00:00",
                    "processed_time": "2024-01-01T00:00:00",
                    "chunk_id": 0,
                    "chunk_size": 91,
                    "split_time": "2024-01-01T00:00:00"
                }
            )
        ]
        
        print(f"ğŸ“ å‡†å¤‡æ·»åŠ  {len(test_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        
        # æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
        result = await vector_manager.add_documents(test_docs)
        
        if result["success"]:
            print("âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸï¼")
            print(f"   æˆåŠŸæ·»åŠ : {result['added_count']} ä¸ªæ–‡æ¡£")
            print(f"   å¤±è´¥æ•°é‡: {result['failed_count']} ä¸ªæ–‡æ¡£")
            print(f"   æˆåŠŸç‡: {result['success_rate']:.1%}")
            
            # æµ‹è¯•æœç´¢åŠŸèƒ½
            print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
            search_results = await vector_manager.search_similar("äººå·¥æ™ºèƒ½", k=2)
            
            print(f"ğŸ“Š æœç´¢ç»“æœ: æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")
            for i, doc in enumerate(search_results, 1):
                print(f"   {i}. {doc.page_content[:50]}...")
                print(f"      æ–‡ä»¶å: {doc.metadata.get('filename', 'N/A')}")
                print(f"      æ¥æº: {doc.metadata.get('source', 'N/A')}")
                print(f"      æ–‡ä»¶å“ˆå¸Œ: {doc.metadata.get('file_hash', 'N/A')}")
            
            return True
        else:
            print("âŒ æ–‡æ¡£æ·»åŠ å¤±è´¥")
            print(f"   é”™è¯¯: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def async_main():
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    success = await test_milvus_schema_fix()
    
    if success:
        print("\nğŸ‰ Milvus schema ä¿®å¤æµ‹è¯•æˆåŠŸï¼")
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. ç°åœ¨å¯ä»¥è¿è¡ŒåŸå§‹è„šæœ¬ scripts/add_test_documents.py")
        print("   2. æ£€æŸ¥ Milvus é›†åˆæ˜¯å¦æ­£ç¡®åˆ›å»ºäº†åŠ¨æ€å­—æ®µ")
    else:
        print("\nâŒ Milvus schema ä¿®å¤æµ‹è¯•å¤±è´¥")
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. å…ˆè¿è¡Œ: python reset_milvus_collection.py")
        print("   2. æ£€æŸ¥ Milvus æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        print("   3. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯")

def main():
    """ä¸»å‡½æ•° - å®‰å…¨è¿è¡Œå¼‚æ­¥ä»£ç """
    if is_async_context():
        print("âš ï¸ æ£€æµ‹åˆ°å¼‚æ­¥ä¸Šä¸‹æ–‡ï¼Œè¯·ç›´æ¥ä½¿ç”¨ await async_main()")
        return async_main()
    else:
        return safe_async_run(async_main())

if __name__ == "__main__":
    result = main()
    if asyncio.iscoroutine(result):
        print("è¯·åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    else:
        sys.exit(0 if result else 1)