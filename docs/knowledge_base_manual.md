# çŸ¥è¯†åº“æ“ä½œè¯´æ˜æ‰‹å†Œ

## æ¦‚è¿°

æœ¬æ‰‹å†Œè¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨çŸ¥è¯†åº“ç³»ç»Ÿè¿›è¡Œæ–‡æ¡£ç®¡ç†ã€å‘é‡åŒ–å­˜å‚¨å’Œæ™ºèƒ½æœç´¢ã€‚

## ç›®å½•

1. [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
2. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
3. [æ–‡æ¡£ä¸Šä¼ ](#æ–‡æ¡£ä¸Šä¼ )
4. [æ‰¹é‡ä¸Šä¼ ](#æ‰¹é‡ä¸Šä¼ )
5. [åˆ†å—ç­–ç•¥](#åˆ†å—ç­–ç•¥)
6. [æœç´¢æµ‹è¯•](#æœç´¢æµ‹è¯•)
7. [ç»Ÿè®¡ä¿¡æ¯](#ç»Ÿè®¡ä¿¡æ¯)
8. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ç³»ç»Ÿæ¶æ„

çŸ¥è¯†åº“ç³»ç»ŸåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

- **æ–‡æ¡£å¤„ç†å™¨**: æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼ˆTXTã€PDFã€DOCXã€MDç­‰ï¼‰
- **åˆ†å—å™¨**: å°†é•¿æ–‡æ¡£åˆ†å‰²æˆé€‚åˆå‘é‡åŒ–çš„å°å—
- **å‘é‡å­˜å‚¨**: ä½¿ç”¨Milvuså­˜å‚¨æ–‡æ¡£å‘é‡
- **åµŒå…¥æ¨¡å‹**: å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
- **æœç´¢å¼•æ“**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ™ºèƒ½æœç´¢

## ç¯å¢ƒé…ç½®

### 1. å¯åŠ¨MilvusæœåŠ¡

```bash
# ä½¿ç”¨Dockerå¯åŠ¨Milvus
docker run -d --name milvus-standalone \
  -p 19530:19530 \
  -v milvus_data:/var/lib/milvus \
  milvusdb/milvus:latest standalone
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. é…ç½®æ–‡ä»¶

æ£€æŸ¥ `config/config.yaml` ä¸­çš„è®¾ç½®ï¼š

```yaml
vector_store:
  type: "milvus"
  host: "localhost"
  port: 19530
  collection_name: "knowledge_base"

embedding:
  model_name: "text-embedding-ada-002"
  
chunking:
  chunk_size: 1000
  chunk_overlap: 200
```

## æ–‡æ¡£ä¸Šä¼ 

### å•æ–‡ä»¶ä¸Šä¼ 

```bash
# ä¸Šä¼ å•ä¸ªæ–‡ä»¶
python scripts/knowledge_base_cli.py add-file path/to/document.txt

# æŒ‡å®šåˆ†å—å¤§å°
python scripts/knowledge_base_cli.py add-file document.pdf --chunk-size 800 --chunk-overlap 150
```

### æ”¯æŒçš„æ–‡ä»¶æ ¼å¼

- **æ–‡æœ¬æ–‡ä»¶**: `.txt`, `.md`
- **PDFæ–‡ä»¶**: `.pdf`
- **Wordæ–‡æ¡£**: `.docx`, `.doc`
- **ç½‘é¡µæ–‡ä»¶**: `.html`

### ä¸Šä¼ ç¤ºä¾‹

```bash
# ä¸Šä¼ Markdownæ–‡ä»¶
python scripts/knowledge_base_cli.py add-file docs/readme.md

# ä¸Šä¼ PDFå¹¶è‡ªå®šä¹‰åˆ†å—
python scripts/knowledge_base_cli.py add-file research.pdf --chunk-size 1200 --chunk-overlap 100
```

## æ‰¹é‡ä¸Šä¼ 

### ç›®å½•æ‰¹é‡ä¸Šä¼ 

```bash
# ä¸Šä¼ æ•´ä¸ªç›®å½•
python scripts/knowledge_base_cli.py add-directory /path/to/documents/

# æŒ‡å®šæ–‡ä»¶ç±»å‹è¿‡æ»¤
python scripts/knowledge_base_cli.py add-directory docs/ --file-types txt,md,pdf

# é€’å½’ä¸Šä¼ å­ç›®å½•
python scripts/knowledge_base_cli.py add-directory docs/ --recursive
```

### æ‰¹é‡ä¸Šä¼ è„šæœ¬

åˆ›å»ºæ‰¹é‡ä¸Šä¼ è„šæœ¬ï¼š

```python
#!/usr/bin/env python3
"""æ‰¹é‡ä¸Šä¼ è„šæœ¬ç¤ºä¾‹"""

import asyncio
from src.knowledge_base.knowledge_base_manager import KnowledgeBaseManager

async def batch_upload():
    kb_manager = KnowledgeBaseManager()
    
    # æ–‡ä»¶åˆ—è¡¨
    files = [
        "docs/manual.pdf",
        "docs/faq.md", 
        "docs/tutorial.txt"
    ]
    
    for file_path in files:
        print(f"ä¸Šä¼ æ–‡ä»¶: {file_path}")
        result = await kb_manager.add_file(file_path)
        print(f"ç»“æœ: {result}")

if __name__ == "__main__":
    asyncio.run(batch_upload())
```

## åˆ†å—ç­–ç•¥

### åˆ†å—å‚æ•°è¯´æ˜

- **chunk_size**: æ¯ä¸ªåˆ†å—çš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆæ¨èï¼š800-1200ï¼‰
- **chunk_overlap**: åˆ†å—é—´é‡å å­—ç¬¦æ•°ï¼ˆæ¨èï¼šchunk_sizeçš„10-20%ï¼‰

### ä¸åŒæ–‡æ¡£ç±»å‹çš„æ¨èè®¾ç½®

| æ–‡æ¡£ç±»å‹ | chunk_size | chunk_overlap | è¯´æ˜ |
|---------|------------|---------------|------|
| æŠ€æœ¯æ–‡æ¡£ | 1000 | 200 | ä¿æŒæŠ€æœ¯æ¦‚å¿µå®Œæ•´æ€§ |
| å°è¯´/æ•…äº‹ | 800 | 150 | ä¿æŒæƒ…èŠ‚è¿è´¯æ€§ |
| å­¦æœ¯è®ºæ–‡ | 1200 | 250 | ä¿æŒè®ºè¯é€»è¾‘å®Œæ•´ |
| FAQæ–‡æ¡£ | 600 | 100 | æ¯ä¸ªé—®ç­”ç‹¬ç«‹åˆ†å— |
| ä»£ç æ–‡æ¡£ | 1500 | 300 | ä¿æŒä»£ç å—å®Œæ•´ |

### è‡ªå®šä¹‰åˆ†å—ç­–ç•¥

```python
from src.document_processing.chunking_strategy import ChunkingStrategy

# åˆ›å»ºè‡ªå®šä¹‰åˆ†å—å™¨
chunker = ChunkingStrategy(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", "ã€‚", ".", " "]
)

# åº”ç”¨åˆ†å—
chunks = chunker.split_text(document_text)
```

## æœç´¢æµ‹è¯•

### åŸºæœ¬æœç´¢

```bash
# åŸºæœ¬æœç´¢
python scripts/knowledge_base_cli.py search "æœºå™¨å­¦ä¹ "

# æŒ‡å®šè¿”å›æ•°é‡
python scripts/knowledge_base_cli.py search "äººå·¥æ™ºèƒ½" -k 5

# æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æ•°
python scripts/knowledge_base_cli.py search "æ·±åº¦å­¦ä¹ " --scores
```

### é«˜çº§æœç´¢

```bash
# å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æœç´¢
python scripts/knowledge_base_cli.py search "ç®—æ³•" --filter "source:algorithm.pdf"

# å¤šå…³é”®è¯æœç´¢
python scripts/knowledge_base_cli.py search "æœºå™¨å­¦ä¹  ç¥ç»ç½‘ç»œ" -k 10
```

### æœç´¢è´¨é‡è¯„ä¼°

#### 1. ç›¸ä¼¼åº¦åˆ†æ•°è§£è¯»

- **0.9-1.0**: æé«˜ç›¸å…³æ€§ï¼Œå‡ ä¹å®Œå…¨åŒ¹é…
- **0.8-0.9**: é«˜ç›¸å…³æ€§ï¼Œå†…å®¹é«˜åº¦ç›¸å…³
- **0.7-0.8**: ä¸­ç­‰ç›¸å…³æ€§ï¼Œæœ‰ä¸€å®šå…³è”
- **0.6-0.7**: ä½ç›¸å…³æ€§ï¼Œå¯èƒ½ç›¸å…³
- **<0.6**: ç›¸å…³æ€§å¾ˆä½ï¼Œå¯èƒ½ä¸ç›¸å…³

#### 2. æœç´¢æ•ˆæœæµ‹è¯•

```python
# åˆ›å»ºæµ‹è¯•è„šæœ¬
test_queries = [
    "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    "æ·±åº¦å­¦ä¹ çš„åº”ç”¨é¢†åŸŸ",
    "å¦‚ä½•é€‰æ‹©ç®—æ³•ï¼Ÿ",
    "æ•°æ®é¢„å¤„ç†æ­¥éª¤"
]

for query in test_queries:
    print(f"\næŸ¥è¯¢: {query}")
    # æ‰§è¡Œæœç´¢å¹¶åˆ†æç»“æœ
```

## ç»Ÿè®¡ä¿¡æ¯

### æŸ¥çœ‹çŸ¥è¯†åº“ç»Ÿè®¡

```bash
# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
python scripts/knowledge_base_cli.py stats
```

### ç»Ÿè®¡ä¿¡æ¯åŒ…å«

- **é›†åˆåç§°**: å‘é‡å­˜å‚¨é›†åˆå
- **æ–‡æ¡£æ•°é‡**: å­˜å‚¨çš„æ–‡æ¡£åˆ†å—æ€»æ•°
- **å¤„ç†ç»Ÿè®¡**: ä¸Šä¼ æˆåŠŸç‡ã€å¤±è´¥æ¬¡æ•°ç­‰
- **æœ€åæ›´æ–°æ—¶é—´**: æœ€è¿‘ä¸€æ¬¡æ›´æ–°æ—¶é—´

### è¯¦ç»†ç»Ÿè®¡è„šæœ¬

```python
#!/usr/bin/env python3
"""è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯è„šæœ¬"""

import asyncio
from src.knowledge_base.knowledge_base_manager import KnowledgeBaseManager

async def detailed_stats():
    kb_manager = KnowledgeBaseManager()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = kb_manager.get_knowledge_base_stats()
    
    print("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  å‘é‡å­˜å‚¨ç»Ÿè®¡: {stats.get('vector_stats', {})}")
    print(f"  å¤„ç†å†å²: {stats.get('processing_stats', {})}")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    test_result = await kb_manager.search("æµ‹è¯•", k=1)
    print(f"  æœç´¢åŠŸèƒ½çŠ¶æ€: {'æ­£å¸¸' if test_result else 'å¼‚å¸¸'}")

if __name__ == "__main__":
    asyncio.run(detailed_stats())
```

## å‘½ä¸­æµ‹è¯•

### 1. å‡†ç¡®æ€§æµ‹è¯•

åˆ›å»ºæµ‹è¯•æŸ¥è¯¢é›†åˆï¼ŒéªŒè¯æœç´¢ç»“æœçš„å‡†ç¡®æ€§ï¼š

```python
#!/usr/bin/env python3
"""æœç´¢å‡†ç¡®æ€§æµ‹è¯•"""

test_cases = [
    {
        "query": "æœºå™¨å­¦ä¹ å®šä¹‰",
        "expected_keywords": ["æœºå™¨å­¦ä¹ ", "ç®—æ³•", "æ•°æ®", "å­¦ä¹ "],
        "min_score": 0.7
    },
    {
        "query": "æ·±åº¦å­¦ä¹ åº”ç”¨",
        "expected_keywords": ["æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "åº”ç”¨"],
        "min_score": 0.6
    }
]

async def accuracy_test():
    kb_manager = KnowledgeBaseManager()
    
    for test_case in test_cases:
        query = test_case["query"]
        results = await kb_manager.search(query, k=3)
        
        print(f"\næµ‹è¯•æŸ¥è¯¢: {query}")
        
        if not results:
            print("âŒ æ— æœç´¢ç»“æœ")
            continue
            
        for i, (doc, score) in enumerate(results):
            print(f"  ç»“æœ {i+1}: åˆ†æ•°={score:.3f}")
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            content = doc.page_content.lower()
            matched_keywords = [
                kw for kw in test_case["expected_keywords"] 
                if kw.lower() in content
            ]
            
            print(f"    åŒ¹é…å…³é”®è¯: {matched_keywords}")
            print(f"    åˆ†æ•°è¾¾æ ‡: {'âœ…' if score >= test_case['min_score'] else 'âŒ'}")

if __name__ == "__main__":
    asyncio.run(accuracy_test())
```

### 2. æ€§èƒ½æµ‹è¯•

```python
#!/usr/bin/env python3
"""æœç´¢æ€§èƒ½æµ‹è¯•"""

import time
import asyncio
from src.knowledge_base.knowledge_base_manager import KnowledgeBaseManager

async def performance_test():
    kb_manager = KnowledgeBaseManager()
    
    queries = [
        "æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "æ·±åº¦å­¦ä¹ ", 
        "ç®—æ³•ä¼˜åŒ–", "æ•°æ®åˆ†æ", "ç¥ç»ç½‘ç»œ"
    ]
    
    total_time = 0
    successful_queries = 0
    
    for query in queries:
        start_time = time.time()
        
        try:
            results = await kb_manager.search(query, k=5)
            end_time = time.time()
            
            query_time = end_time - start_time
            total_time += query_time
            successful_queries += 1
            
            print(f"æŸ¥è¯¢: {query}")
            print(f"  è€—æ—¶: {query_time:.3f}ç§’")
            print(f"  ç»“æœæ•°: {len(results)}")
            
        except Exception as e:
            print(f"æŸ¥è¯¢å¤±è´¥: {query} - {e}")
    
    if successful_queries > 0:
        avg_time = total_time / successful_queries
        print(f"\næ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.3f}ç§’")
        print(f"  æˆåŠŸæŸ¥è¯¢æ•°: {successful_queries}/{len(queries)}")

if __name__ == "__main__":
    asyncio.run(performance_test())
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. Milvusè¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥MilvusæœåŠ¡çŠ¶æ€
docker ps | grep milvus

# é‡å¯MilvusæœåŠ¡
docker restart milvus-standalone
```

#### 2. æ–‡æ¡£ä¸Šä¼ å¤±è´¥

- æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
- æŸ¥çœ‹é”™è¯¯æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯

#### 3. æœç´¢ç»“æœä¸å‡†ç¡®

- è°ƒæ•´åˆ†å—å¤§å°å’Œé‡å å‚æ•°
- æ£€æŸ¥åµŒå…¥æ¨¡å‹æ˜¯å¦é€‚åˆæ–‡æ¡£ç±»å‹
- å¢åŠ è®­ç»ƒæ•°æ®é‡

#### 4. ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤ºN/A

- æ£€æŸ¥å‘é‡å­˜å‚¨è¿æ¥
- ç¡®è®¤é›†åˆæ˜¯å¦æ­£ç¡®åˆ›å»º
- æŸ¥çœ‹æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python scripts/knowledge_base_cli.py search "test" --verbose

# å¯ç”¨è°ƒè¯•æ¨¡å¼
export LOG_LEVEL=DEBUG
python scripts/knowledge_base_cli.py stats
```

### æ•°æ®å¤‡ä»½ä¸æ¢å¤

```bash
# å¯¼å‡ºçŸ¥è¯†åº“æ•°æ®
python scripts/export_knowledge_base.py --output backup.json

# æ¢å¤çŸ¥è¯†åº“æ•°æ®
python scripts/import_knowledge_base.py --input backup.json
```

## æœ€ä½³å®è·µ

### 1. æ–‡æ¡£å‡†å¤‡

- ç¡®ä¿æ–‡æ¡£å†…å®¹æ¸…æ™°ã€ç»“æ„åŒ–
- ç§»é™¤ä¸å¿…è¦çš„æ ¼å¼å’Œç‰¹æ®Šå­—ç¬¦
- ä¸ºé‡è¦æ–‡æ¡£æ·»åŠ å…ƒæ•°æ®æ ‡ç­¾

### 2. åˆ†å—ä¼˜åŒ–

- æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©åˆé€‚çš„åˆ†å—å¤§å°
- ä¿æŒé‡è¦æ¦‚å¿µåœ¨åŒä¸€åˆ†å—å†…
- å®šæœŸæµ‹è¯•å’Œè°ƒæ•´åˆ†å—å‚æ•°

### 3. æœç´¢ä¼˜åŒ–

- ä½¿ç”¨å…·ä½“ã€æ˜ç¡®çš„æŸ¥è¯¢è¯
- ç»“åˆå¤šä¸ªå…³é”®è¯æé«˜å‡†ç¡®æ€§
- æ ¹æ®ç»“æœåé¦ˆè°ƒæ•´æœç´¢ç­–ç•¥

### 4. ç»´æŠ¤ç®¡ç†

- å®šæœŸæ¸…ç†è¿‡æ—¶æ–‡æ¡£
- ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
- å¤‡ä»½é‡è¦æ•°æ®

## è”ç³»æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–é”™è¯¯è¯¦æƒ…
2. å‚è€ƒæœ¬æ‰‹å†Œçš„æ•…éšœæ’é™¤éƒ¨åˆ†
3. æäº¤Issueå¹¶é™„ä¸Šè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

---

*æœ€åæ›´æ–°: 2025-01-29*