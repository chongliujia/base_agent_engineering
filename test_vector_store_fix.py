#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„å‘é‡å­˜å‚¨ç®¡ç†å™¨
"""
import os
import sys
import asyncio
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from langchain_core.documents import Document
from src.knowledge_base.vector_store_manager import VectorStoreManager

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

async def test_vector_store():
    """æµ‹è¯•å‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    print("ğŸ” æµ‹è¯•å‘é‡å­˜å‚¨ç®¡ç†å™¨...")
    
    try:
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
        vs_manager = VectorStoreManager()
        print("âœ… å‘é‡å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_docs = [
            Document(
                page_content="è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼ŒåŒ…å«äººå·¥æ™ºèƒ½çš„åŸºç¡€çŸ¥è¯†ã€‚",
                metadata={"source": "test1.txt", "type": "test"}
            ),
            Document(
                page_content="è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œä»‹ç»æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€‚",
                metadata={"source": "test2.txt", "type": "test"}
            )
        ]
        
        print(f"ğŸ“ å‡†å¤‡æ·»åŠ  {len(test_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        
        # æµ‹è¯•æ·»åŠ æ–‡æ¡£
        result = await vs_manager.add_documents(test_docs)
        
        print("ğŸ“Š æ·»åŠ ç»“æœ:")
        print(f"   æˆåŠŸ: {result.get('success', False)}")
        print(f"   æ€»æ–‡æ¡£æ•°: {result.get('total_documents', 0)}")
        print(f"   æˆåŠŸæ·»åŠ : {result.get('added_count', 0)}")
        print(f"   å¤±è´¥æ•°é‡: {result.get('failed_count', 0)}")
        print(f"   æˆåŠŸç‡: {result.get('success_rate', 0)}%")
        
        if result.get('success', False):
            print("âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸï¼")
            
            # æµ‹è¯•æœç´¢
            print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
            search_results = await vs_manager.search_similar("äººå·¥æ™ºèƒ½", k=2)
            
            print(f"ğŸ“‹ æœç´¢ç»“æœ: {len(search_results)} ä¸ªæ–‡æ¡£")
            for i, doc in enumerate(search_results):
                print(f"   {i+1}. {doc.page_content[:50]}...")
        else:
            print("âŒ æ–‡æ¡£æ·»åŠ å¤±è´¥")
            if 'batch_results' in result:
                for batch_result in result['batch_results']:
                    if not batch_result.get('success', True):
                        print(f"   é”™è¯¯: {batch_result.get('error', 'Unknown error')}")
        
        return result.get('success', False)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ä¿®å¤åçš„å‘é‡å­˜å‚¨...")
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        exit(1)
    
    print(f"ğŸ”‘ API Key: {api_key[:10]}...")
    
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(test_vector_store())
    
    if success:
        print("\nğŸ‰ å‘é‡å­˜å‚¨æµ‹è¯•æˆåŠŸï¼ç°åœ¨å¯ä»¥è¿è¡ŒåŸå§‹è„šæœ¬äº†ã€‚")
    else:
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥ Milvus æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        print("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   3. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯")