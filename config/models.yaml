# 简化模型配置文件
# 只保留OpenAI和DashScope重排序模型

# LangChain聊天模型配置
chat_models:
  # OpenAI模型
  primary:
    name: "qwen-plus"
    provider: "langchain_openai"
    class: "ChatOpenAI"
    api_key_env: "DASHSCOPE_API_KEY"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    parameters:
      temperature: 0.7
      max_tokens: 2000
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      streaming: true
    cost_per_1k_tokens: 0.03
    max_context_length: 8192
    
  fallback:
    name: "qwen-plus"
    provider: "langchain_openai"
    class: "ChatOpenAI"
    api_key_env: "DASHSCOPE_API_KEY"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    parameters:
      temperature: 0.7
      max_tokens: 1500
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
      streaming: true
    cost_per_1k_tokens: 0.002
    max_context_length: 4096

# LangChain嵌入模型配置
embedding_models:
  # DashScope嵌入模型 (通义千问)
  primary:
    name: "text-embedding-v4"
    provider: "langchain_community"
    class: "DashScopeEmbeddings"
    api_key_env: "DASHSCOPE_API_KEY"
    parameters:
      model: "text-embedding-v4"
      dashscope_api_key: "${DASHSCOPE_API_KEY}"
    cost_per_1k_tokens: 0.0005
    max_input_length: 8192
    batch_size: 10
    
  fallback:
    name: "text-embedding-v3"
    provider: "langchain_community"
    class: "DashScopeEmbeddings"
    api_key_env: "DASHSCOPE_API_KEY"
    parameters:
      model: "text-embedding-v3"
      dashscope_api_key: "${DASHSCOPE_API_KEY}"
    cost_per_1k_tokens: 0.0005
    max_input_length: 8192
    batch_size: 10

# 重排序模型配置
reranking_models:
  # 通义千问重排序模型 (使用DashScope原生API)
  primary:
    name: "gte-rerank-v2"
    provider: "dashscope"
    class: "DashScopeRerank"
    api_key_env: "DASHSCOPE_API_KEY"
    parameters:
      model: "gte-rerank-v2"
      return_documents: true
      top_n: 10
    batch_size: 20
    cost_per_1k_tokens: 0.0004

# LangChain向量存储配置
vector_stores:
  primary:
    name: "milvus"
    provider: "langchain_milvus"
    class: "Milvus"
    connection_args:
      host: "${MILVUS_HOST:localhost}"
      port: "${MILVUS_PORT:19530}"
      user: "${MILVUS_USER:}"
      password: "${MILVUS_PASSWORD:}"
    collection_name: "knowledge_base"
    # 启用动态字段支持，允许添加任意 metadata 字段
    enable_dynamic_field: true
    # 设置自动生成主键
    auto_id: true
    # 删除旧集合（开发阶段）
    drop_old: false

# LangChain文档加载器配置
document_loaders:
  pdf:
    class: "PyPDFLoader"
    provider: "langchain_community"
  docx:
    class: "Docx2txtLoader"
    provider: "langchain_community"
  txt:
    class: "TextLoader"
    provider: "langchain_community"
  md:
    class: "UnstructuredMarkdownLoader"
    provider: "langchain_unstructured"
  web:
    class: "WebBaseLoader"
    provider: "langchain_community"

# LangChain文本分割器配置
text_splitters:
  recursive:
    class: "RecursiveCharacterTextSplitter"
    provider: "langchain_core"
    parameters:
      chunk_size: 1000
      chunk_overlap: 200
      separators: ["\n\n", "\n", " ", ""]
      
  semantic:
    class: "SemanticChunker"
    provider: "langchain_experimental"
    parameters:
      embeddings: "primary"
      breakpoint_threshold_type: "percentile"
      
  token:
    class: "TokenTextSplitter"
    provider: "langchain_core"
    parameters:
      chunk_size: 1000
      chunk_overlap: 200

# LangGraph工作流配置
langgraph:
  # RAG工作流配置
  rag_workflow:
    nodes:
      - query_analyzer
      - retrieval_router
      - knowledge_retriever
      - web_searcher
      - information_fusion
      - context_builder
      - response_generator
    
    edges:
      - from: "query_analyzer"
        to: "retrieval_router"
      - from: "retrieval_router"
        to: ["knowledge_retriever", "web_searcher"]
      - from: ["knowledge_retriever", "web_searcher"]
        to: "information_fusion"
      - from: "information_fusion"
        to: "context_builder"
      - from: "context_builder"
        to: "response_generator"
    
    # 条件路由配置
    conditional_edges:
      retrieval_router:
        conditions:
          - condition: "needs_knowledge_base"
            next: "knowledge_retriever"
          - condition: "needs_web_search"
            next: "web_searcher"
          - condition: "needs_both"
            next: ["knowledge_retriever", "web_searcher"]

# LangSmith配置（可选）
langsmith:
  enabled: false
  api_key_env: "LANGSMITH_API_KEY"
  project_name: "base-agent-engineering"
  tracing: true

# 默认模型选择
default_models:
  chat: "primary"
  embedding: "primary"
  reranking: "primary"
  vector_store: "primary"
  text_splitter: "recursive"

# 模型切换策略
model_switching:
  enabled: true
  fallback_chain:
    chat: ["primary", "fallback"]
    embedding: ["primary", "fallback"]
    reranking: ["primary"]
  
  # 自动切换条件
  switch_conditions:
    rate_limit: true      # 遇到速率限制时切换
    api_error: true       # API错误时切换
    timeout: true         # 超时时切换
    cost_threshold: 100   # 成本超过阈值时切换到便宜模型

# 性能优化配置
performance:
  # 并发控制
  max_concurrent_requests:
    chat: 10
    embedding: 20
    reranking: 15
  
  # 缓存配置
  cache:
    enabled: true
    ttl: 3600  # 1小时
    max_size: 1000
    
  # 批处理配置
  batch_processing:
    enabled: true
    max_batch_size:
      embedding: 100
      reranking: 32
    batch_timeout: 5.0  # 5秒

# 监控配置
monitoring:
  # 日志配置
  logging:
    level: "INFO"
    format: "json"
    include_tokens: true
    include_cost: true
  
  # 成本监控
  cost_tracking:
    enabled: true
    daily_limit: 50.0   # 每日成本限制（美元）
    alert_threshold: 0.8  # 80%时告警
  
  # 性能监控
  performance_tracking:
    enabled: true
    response_time_threshold: 10.0  # 10秒
    error_rate_threshold: 0.05     # 5%错误率